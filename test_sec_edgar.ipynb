{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import requests_random_user_agent\n",
    "import sys, os, json, time, re, sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "from sqlite3 import Error\n",
    "\n",
    "\n",
    "# url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "PARAMS = {\"action\": \"getcompany\", \"CIK\": Company_CIK_Number, \"type\": Filing_Type, \"dateb\": \"\", \"owner\": \"exclude\", \"start\": \"\", \"output\": \"\", \"count\": \"100\" }\n",
    "company_CIKs = [\"1018724\", \"1318605\", \"789019\", \"320193\"]\n",
    "filing_types = [\"10-K\"]\n",
    "db_name = \"edgar.db\"\n",
    "folder_path = r\"/home/rocket/Code/Projects/Py/SECdb/sqlite\"  # convert to win64 'C:\\'\n",
    "db_path = f\"{folder_path}/{db_name}\"\n",
    "\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2022-08-31\"\n",
    "\n",
    "\n",
    "# class DB_Connection:\n",
    "\n",
    "    \"\"\"Initialize obj attrs\"\"\"\n",
    "\n",
    "    def __init__(self, db_name, folder_path, db_path):\n",
    "        self.db_name = db_name\n",
    "        self.folder_path = folder_path\n",
    "\n",
    "    \"\"\" Create a directory for the DB file if the directory doesnt exist.\"\"\"\n",
    "\n",
    "    def create_folder(self):\n",
    "        if not os.path.exists(self.folder_path):\n",
    "            os.makedirs(self.folder_path)\n",
    "            print(f\"Successfully created the new folder path {self.folder_path}\")\n",
    "        else:\n",
    "            print(f\"Folder path {self.folder_path} already exists.\")\n",
    "\n",
    "    # Open connection to the db, if the connection fails then abort.\n",
    "    # If db file doesn't exist, automatically create itself.\n",
    "    @classmethod\n",
    "    def open_con(cls, db_path):\n",
    "        try:\n",
    "            cls.conn = sqlite3.connect(db_path)\n",
    "            print(f\"Successfully connected to the {db_path} \")\n",
    "            return cls.conn\n",
    "        except sqlite3.Error as e:\n",
    "            print(\n",
    "                f\"Error occured, unable to connect to the {db_path} database.\\n{e}\\nAborting program\"\n",
    "            )\n",
    "            sys.exit(1)\n",
    "\n",
    "    # close connection to the db.\n",
    "    @classmethod\n",
    "    def close_conn(cls):\n",
    "        try:\n",
    "            cls.conn.commit()\n",
    "            print(\"Comitted transactions.\")\n",
    "            cls.conn.close()\n",
    "            print(\"Closing all databse connections\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unable to close database connection.\\n{e}\")\n",
    "\n",
    "\n",
    "# class Filing_Links:\n",
    "\n",
    "    def __init__(self, company_CIKs, filing_types, start_date, end_date):\n",
    "        # self.filing_types = [ item.upper() for item in self.filing_types ]\n",
    "        self.company_CIKs = company_CIKs\n",
    "        # # Capitalize the letters of the forms, by default sqlite is case sensitive.\n",
    "        self.filing_types = [item.upper() for item in filing_types]\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "\n",
    "    # Get all available filings for the specified CIKS and their respective links.\n",
    "    def Get_FLinks(self):\n",
    "        try:\n",
    "            for Company_CIK_Number in self.company_CIKs:\n",
    "                for Filing_Type in self.filing_types:\n",
    "                    # define the params dict\n",
    "                    filing_params = {\n",
    "                        \"action\": \"getcompany\",\n",
    "                        \"CIK\": Company_CIK_Number,\n",
    "                        \"type\": Filing_Type,\n",
    "                        \"dateb\": \"\",\n",
    "                        \"owner\": \"exclude\",\n",
    "                        \"start\": \"\",\n",
    "                        \"output\": \"\",\n",
    "                        \"count\": \"100\",\n",
    "                    }\n",
    "                    # req the url & parse response.\n",
    "                    response = req.get(\n",
    "                        url=r\"https://www.sec.gov/cgi-bin/browse-edgar\",\n",
    "                        params=filing_params,\n",
    "                    )\n",
    "\n",
    "                    # add 1/10th sec delay to comply w/ SEC.gov's 10req/s limit (see robots.txt)\n",
    "                    time.sleep(0.1)\n",
    "                    soup = bs4(response.content, \"html.parser\")\n",
    "                    # Find doc table that contains filing info\n",
    "                    main_table = soup.find_all(\"table\", class_=\"tableFile2\")\n",
    "                    # base url will be used to construct doc link urls\n",
    "                    sec_base_url = r\"https://www.sec.gov\"\n",
    "                    Company_Name_path = str(soup.find(\"span\", {\"class\": \"companyName\"}))\n",
    "                    if Company_Name_path != None:\n",
    "                        try:\n",
    "                            Company_Name = re.search( '<span class=\"companyName\">(.*)<acronym title',\n",
    "                                                    Company_Name_path).group(1)\n",
    "                        except AttributeError:\n",
    "                            print(f\"Couldn't find company name, \\\n",
    "                                       assigning NULL value to company name.\")\n",
    "                            Company_Name = None\n",
    "                    # loop through ea row of the table & extract filing numbers, links, etc.\n",
    "                    for row in main_table[0].find_all(\"tr\"):\n",
    "                        # find all of the rows under the 'td' element.\n",
    "                        cols = row.find_all(\"td\")\n",
    "                        # if no info was detected, move onto the next row.\n",
    "                        if len(cols) != 0:\n",
    "                            # get the text from the table.\n",
    "                            Filing_Type = cols[0].text.strip()\n",
    "                            Filing_Date = cols[3].text.strip()\n",
    "                            Filing_Number = cols[4].text.strip()\n",
    "                            Filing_Number = \"\".join(\n",
    "                                e for e in Filing_Number if e.isalnum()\n",
    "                            )\n",
    "\n",
    "                            # Get the URL path to the filing number.\n",
    "                            filing_number_path = cols[4].find(\"a\")\n",
    "                            if filing_number_path != None:\n",
    "                                Filing_Number_Link = sec_base_url + filing_number_path[\"href\"]\n",
    "                            else:\n",
    "                                break\n",
    "\n",
    "                            # Get the URL path to the doc.\n",
    "                            document_link_path = cols[1].find(\"a\", {\"href\": True, \"id\": \"documentsbutton\"})\n",
    "                            if document_link_path != None:\n",
    "                                Document_Link = sec_base_url + document_link_path[\"href\"]\n",
    "                            else:\n",
    "                                Document_Link = None\n",
    "                            try:\n",
    "                                Account_Number = cols[2].text.strip()\n",
    "                                Account_Number = re.search(\"Acc-no:(.*)(34 Act)\", Account_Number).group(1)\n",
    "                                Account_Number = \"\".join(e for e in Account_Number if e.isalnum())\n",
    "                            except Exception as e:\n",
    "                                \"\"\"\n",
    "                                Add break if you dont want empty rows of account numbers. If account numbers arent\n",
    "                                present, the interactive document link wont be available. If the interactive link\n",
    "                                  isnt present, we wont be able to extract the individual tables containing\n",
    "                                   financial statements.\n",
    "                                \"\"\"\n",
    "                                Account_Number = None\n",
    "                                print(f\"Couldnt retrieve the account number, assigning NULL value.\\n{e}\")\n",
    "\n",
    "                        # Get the URL path to the interactive documents\n",
    "                        interact_data_path = cols[1].find(\"a\", {\"href\": True, \"id\": \"interactiveDataBtn\"})\n",
    "                        if interact_data_path != None:\n",
    "                            Interactive_Data_Link = sec_base_url + interact_data_path[\"href\"]\n",
    "                            # If the interactive data link exists, then so does the FilingSummary.xml link\n",
    "                            Xml_Summary = Document_Link.replace(f\"{Account_Number}\", \"\")\\\n",
    "                                                       .replace(\"-\", \"\")\\\n",
    "                                                       .replace(\"index.htm\", \"/FilingSummary.xml\")\n",
    "                        else:\n",
    "                            # break ...?\n",
    "                            Interactive_Data_Link = None\n",
    "                            Xml_Summary = None\n",
    "\n",
    "                        self.info_to_sql(\n",
    "                            Company_Name,\n",
    "                            Company_CIK_Number,\n",
    "                            Account_Number,\n",
    "                            Filing_Type,\n",
    "                            Filing_Number,\n",
    "                            Filing_Date,\n",
    "                            Document_Link,\n",
    "                            Interactive_Data_Link,\n",
    "                            Filing_Number_Link,\n",
    "                            Xml_Summary,\n",
    "                        )\n",
    "        except Exception as e:\n",
    "            print(f\"Couldnt retrieve the table containing the necessary info. \\\n",
    "                    \\nAborting the program.\\nIf index list is out of range, \\\n",
    "                    that you entered the correct CIK number(s).\"\n",
    "                    )\n",
    "            sys.exit(1)\n",
    "\n",
    "    # Migrate the df containing the filing & document links to a local sqlite db.\n",
    "    def info_to_sql(\n",
    "        self,\n",
    "        Company_Name,\n",
    "        Company_CIK_Number,\n",
    "        Account_Number,\n",
    "        Filing_Type,\n",
    "        Filing_Number,\n",
    "        Filing_Date,\n",
    "        Document_Link,\n",
    "        Interactive_Data_Link,\n",
    "        Filing_Number_Link,\n",
    "        Xml_Summary,\n",
    "    ):\n",
    "\n",
    "        with DB_Connection.open_con(self.db_path) as conn:\n",
    "            try:\n",
    "                with closing(conn.cursor()) as cursor:\n",
    "                    cursor.execute(\n",
    "                        \"\"\"\n",
    "                        CREATE TABLE IF NOT EXISTS filing_list (\n",
    "                        filing_number integer PRIMARY KEY,\n",
    "                        account_number integer,\n",
    "                        company_name text NOT NULL,\n",
    "                        cik integer NOT NULL,\n",
    "                        filing_type text NOT NULL,\n",
    "                        filing_date text NOT NULL,\n",
    "                        document_link_html TEXT NOT NULL,\n",
    "                        filing_number_link TEXT NOT NULL,\n",
    "                        interactive_dash_link TEXT,\n",
    "                        xml_summary TEXT\n",
    "                        )\n",
    "                        ;\"\"\"\n",
    "                    )\n",
    "            except ValueError as e:\n",
    "                print(f\"Error occured while attempting to create the filing_list table.\\\n",
    "                        \\nAborting the program.\"\n",
    "                )\n",
    "                sys.exit(1)\n",
    "            else:\n",
    "                print(f\"Successfully created the table.\")\n",
    "                print(\n",
    "                    f\"Migrating info for filing number {Filing_Number} to the SQL table...\"\n",
    "                )\n",
    "                try:\n",
    "                    # Insert or IGNORE will insert a record if it doesnt duplicate an existing record.\n",
    "                    with closing(conn.cursor()) as cursor:\n",
    "                        cursor.execute(\n",
    "                            \"\"\"\n",
    "                        INSERT or IGNORE INTO filing_list (\n",
    "                        filing_number,\n",
    "                        account_number,\n",
    "                        company_name,\n",
    "                        cik,\n",
    "                        filing_type,\n",
    "                        filing_date,\n",
    "                        document_link_html,\n",
    "                        filing_number_link,\n",
    "                        interactive_dash_link,\n",
    "                        summary_link_xml\n",
    "                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?) \"\"\",\n",
    "                            (\n",
    "                                Filing_Number,\n",
    "                                Account_Number,\n",
    "                                Company_Name,\n",
    "                                Company_CIK_Number,\n",
    "                                Filing_Type,\n",
    "                                Filing_Date,\n",
    "                                Document_Link,\n",
    "                                Filing_Number_Link,\n",
    "                                Interactive_Data_Link,\n",
    "                                Xml_Summary,\n",
    "                            ),\n",
    "                        )\n",
    "                except ValueError as e:\n",
    "                    print(\n",
    "                        f\"Error occured while attempting to insert values into the filing_list table.\\n{e}\"\n",
    "                    )\n",
    "\n",
    "        DB_Connection.close_conn()\n",
    "\n",
    "    # Extract individual table links to financial statements, supplementary data tables, etc (everything?)\n",
    "    def get_table_links(self):\n",
    "        dfs = []\n",
    "        with DB_Connection.open_con(self.db_path) as conn:\n",
    "            try:\n",
    "                for Company_CIK_Number in self.company_CIKs:\n",
    "                    for Filing_Type in self.filing_types:\n",
    "                        df = pd.read_sql_query(\n",
    "                            \"\"\"\n",
    "                            SELECT filing_number, xml_summary\n",
    "                            FROM filing_list\n",
    "                            WHERE xml_summary IS NOT NULL\n",
    "                            AND filing_type = ?\n",
    "                            AND cik = ?\n",
    "                            AND filing_date BETWEEN ? AND ?\n",
    "                            \"\"\",\n",
    "                            con=conn,\n",
    "                            params=(\n",
    "                                Filing_Type,\n",
    "                                Company_CIK_Number,\n",
    "                                self.start_date,\n",
    "                                self.end_date,\n",
    "                            ),\n",
    "                        )\n",
    "                        dfs.append(df)\n",
    "                df_query2 = pd.concat(dfs)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error occured while attempting to retireve data from filing_list table.\\n{e}\"\n",
    "                )\n",
    "                sys.exit(1)\n",
    "\n",
    "            # If the df is empty, exit.\n",
    "            if len(df_query2) == 0:\n",
    "                error_msg = (\n",
    "                    \"Dataframe is empty. (Error in the get_table_links method.) \"\n",
    "                )\n",
    "                sys.exit(1)\n",
    "            try:\n",
    "                with closing(conn.cursor()) as cursor:\n",
    "                    cursor.execute(\n",
    "                        \"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS individual_report_links (\n",
    "                    filing_number integer,\n",
    "                    short_name text,\n",
    "                    report_url text,\n",
    "                    FOREIGN KEY(filing_number) REFERENCES filing_list(filing_number),\n",
    "                    UNIQUE(report_url)\n",
    "                    )\n",
    "                    ;\"\"\"\n",
    "                    )\n",
    "            except ValueError as e:\n",
    "                print(\n",
    "                    f\"Error occured while attempting to create individual_report_links table.\\n{e}\"\n",
    "                )\n",
    "                sys.exit(1)\n",
    "\n",
    "            # Extract the tables name and its respective URL\n",
    "            # Currently, there isnt a function/method(?) to extract data from the .xml extension\n",
    "            for filing_number, xml_summary in df_query2.itertuples(index=False):\n",
    "                resp_2 = req.get(xml_summary).content\n",
    "                time.sleep(0.1)\n",
    "                soup_2 = bs4(resp_2, \"lxml\")\n",
    "                for item in soup_2.find_all(\"report\")[:-1]:\n",
    "                    if item.shortname:\n",
    "                        Short_Name = item.shortname.text\n",
    "                        # Remove special/unicode/ascii characters && whitespace end of string\n",
    "                        Short_Name = re.sub(r\"[^a-zA-Z0-9]+\", \" \", Short_Name)\n",
    "                        Short_Name = Short_Name.rstrip()\n",
    "                    else:\n",
    "                        print(f\"Short name couldnt be retrieved.\")\n",
    "                        Short_Name = None\n",
    "                    # some tables come only in xml form...\n",
    "                    if item.htmlfilename:\n",
    "                        Report_Url = xml_summary.replace(\n",
    "                            \"FilingSummary.xml\", item.htmlfilename.text\n",
    "                        )\n",
    "                    elif item.xmlfilename:\n",
    "                        Report_Url = xml_summary.replace(\n",
    "                            \"FilingSummary.xml\", item.xmlfilename.text\n",
    "                        )\n",
    "                    else:\n",
    "                        print(f\"URL to the individual report couldnt be retrieved.\")\n",
    "                        Report_Url = None\n",
    "\n",
    "                    print(Short_Name)\n",
    "                    print(Report_Url)\n",
    "                    print(filing_number)\n",
    "                    print(\n",
    "                        \"*\" * 50 + \" Inserting values into the table .... \" + \"*\" * 50\n",
    "                    )\n",
    "\n",
    "                    try:\n",
    "                        with closing(conn.cursor()) as cursor:\n",
    "                            cursor.execute(\n",
    "                                \"\"\"\n",
    "                            INSERT OR IGNORE INTO individual_report_links (\n",
    "                            filing_number,\n",
    "                            short_name,\n",
    "                            report_url\n",
    "                            ) VALUES (?, ?, ?) \"\"\",\n",
    "                                (filing_number, Short_Name, Report_Url),\n",
    "                            )\n",
    "                    except ValueError as e:\n",
    "                        print(\n",
    "                            f\"Error occured while attempting to insert values into \\\n",
    "                                  the individual_report_links table.\\nAborting the program.\\n{e}\"\n",
    "                        )\n",
    "                        sys.exit(1)\n",
    "    DB_Connection.close_conn()\n",
    "# class Extract_Data:\n",
    "    def __init__(self):\n",
    "        self.df_xml = None\n",
    "\n",
    "    # extract table data from a xml\n",
    "    def html_table_extractor(self, report_url):\n",
    "        # Note to self, .text is unicode u\"\", .content is in byes b\"\"\n",
    "        response_xml = req.get(report_url).content\n",
    "        time.sleep(0.1)\n",
    "        xml_soup = bs4(response_xml, \"lxml\")\n",
    "        table = xml_soup.find_all(\"table\")\n",
    "        if table:\n",
    "            try:\n",
    "                print(\"Insert table data into the dataframe.\")\n",
    "                self.df_xml = pd.read_html(str(table))[0]\n",
    "                self.df_xml = (\n",
    "                    self.df_xml.replace({\"\\$\": \"\"}, regex=True)\n",
    "                    .replace({\"\\)\": \"\"}, regex=True)\n",
    "                    .replace({\"\\(\": \"\"}, regex=True)\n",
    "                    .replace({\"\\%\": \"\"}, regex=True)\n",
    "                    .replace({\" \", \"\", 1}, regex=True)\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error occurred while attempting to insert \\\n",
    "                        table data into the DataFrame.\\n{e}\"\n",
    "                )\n",
    "        else:\n",
    "            print(f\"No table detected for {report_url}.\")\n",
    "\n",
    "    # Retrieve necessary information to extract data from the table's URL.\n",
    "    def get_tables(self):\n",
    "        dfs = []\n",
    "        with DB_Connection.open_con(self.db_path) as conn:\n",
    "            for company_CIK in filings1.company_CIKs:\n",
    "                for filing_type in filings1.filingstypes:\n",
    "                    try:\n",
    "                        df = pd.read_sql_query(\n",
    "                            \"\"\"\n",
    "                            SELECT a.filing_number,\n",
    "                                   a.company_name,\n",
    "                                   a.filing_type,\n",
    "                                   a.filing_date,\n",
    "                                   b.short_name,\n",
    "                                   b.report_url\n",
    "                            FROM filing_list a\n",
    "                            INNER JOIN individual_report_links b\n",
    "                            ON a.filing_number = b.filing_number\n",
    "                            WHERE b.report_url LIKE '%.htm%'\n",
    "                            AND a.cik = ?\n",
    "                            AND a.filing_type = ?\n",
    "                            AND a.filing_date BETWEEN ? AND ?\n",
    "                            ORDER by filing_date DESC\n",
    "                            LIMIT ?\n",
    "                            \"\"\",\n",
    "                            con=conn,\n",
    "                            params=(\n",
    "                                company_CIK,\n",
    "                                filing_type,\n",
    "                                filings1.start_date,\n",
    "                                filings1.end_date,\n",
    "                                10,\n",
    "                            ),\n",
    "                        )\n",
    "                        dfs.append(df)\n",
    "                    except ValueError as e:\n",
    "                        print(\n",
    "                            f\"Error occured while attempting to retrieve data \\\n",
    "                                from the SQL db.\\nAborting the program.\\n{e}\"\n",
    "                        )\n",
    "                        sys.exit(1)\n",
    "\n",
    "            df_query1 = pd.concat(dfs)\n",
    "            # if the df is empty, terminate the program.\n",
    "            if len(df_query1) == 0:\n",
    "                print(\"Dataframe is empty, aborting the program. Aborting the program\")\n",
    "                sys.exit(1)\n",
    "            else:\n",
    "                # if max recursion error occurs, increase recursion limit. sys.setrecursionlimit(25000)\n",
    "                pass\n",
    "            for filing_number,\\\n",
    "                company_name,\\\n",
    "                filing_type,\\\n",
    "                filing_date,\\\n",
    "                short_name,\\\n",
    "                report_url,\\\n",
    "                in df_query1.itertuples(index=False):\n",
    "                print(f\"Processing {short_name} table at {report_url}.\")\n",
    "\n",
    "                if report_url.endswith(\".htm\"):\n",
    "                    try:\n",
    "                        self.html_table_extractor(report_url)\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Couldnt retrieve the table for filing number {filing_number} at {report_url}\\n{e}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        try:\n",
    "                            # want to name the table with a unique table name for easy reference\n",
    "                            table_name = filing_type + filing_date + \"_\" + \\\n",
    "                                short_name.replace(\" \", \"_\") + \"_\" + str(filing_number)\n",
    "                            # remove all special chars (unicode, ascii) except '_'\n",
    "                            table_name = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", table_name)\n",
    "                            print(f\"Inserting data from the dataframe into SQL table {table_name}\")\n",
    "                            # check to see if the table already exists in db to avoid duplication\n",
    "                            with closing(conn.cursor()) as cursor:\n",
    "                                cursor.execute( f\"\"\" SELECT count(name)\n",
    "                                                FROM sqlite_master\n",
    "                                                WHERE type='table' AND name= '{table_name}' \"\"\")  # SQL injection much?\n",
    "                                # if count is 1 -> table exists\n",
    "                                if cursor.fetchone()[0] == 1:\n",
    "                                    print(f\"Table {table_name} already exists.\")\n",
    "                                else:\n",
    "                                    # Write records that are stored in the Dataframe into a SQL server database.\n",
    "                                    self.df_xml.to_sql(con = conn,\n",
    "                                            name = table_name,\n",
    "                                            schema = \"SCHEMA\",\n",
    "                                            index = False,\n",
    "                                            if_exists = \"fail\")\n",
    "                        except ValueError as e:\n",
    "                            print(f\"Couldnt migrate the {short_name} table to the SQL database.\\n{e}\")\n",
    "                elif report_url.endswith(\".xml\"):\n",
    "                    print(\".xml extension link detected. Unable to process the table.\\\n",
    "                           .xml extension link support will be developed in the future.\"\n",
    "                    )\n",
    "                else:\n",
    "                    print(f\"Table for filing number {filing_number} couldnt be detected.\")\n",
    "\n",
    "        DB_Connection.close_conn()\n",
    "\n",
    "    # Normalizing data.\n",
    "    def transpose(self):\n",
    "\n",
    "        db2_path = self.db_path.replace(\".db\", \"_transposed;db\")\n",
    "        with DB_Connection.open_con(self.db_path) as conn:\n",
    "            try:\n",
    "                df_table_list = pd.read_sql_query(\n",
    "                    \"\"\"\n",
    "                    SELECT name AS table_name\n",
    "                    FROM sqlite_master\n",
    "                    WHERE type='table'\n",
    "                    \"\"\",\n",
    "                    conn,\n",
    "                )\n",
    "            except ValueError as e:\n",
    "                print(f\"Couldnt retrieve table list.\\n{e}\")\n",
    "            for row in df_table_list.itertuples(index=False):\n",
    "                try:\n",
    "                    df_table = pd.read_sql_query(\n",
    "                        \"\"\" SELECT * FROM \"{}\" \"\"\".format(row.table_name), con=conn\n",
    "                    )\n",
    "                except ValueError as e:\n",
    "                    print(f\"couldnt read table {table_name}.\\n{e}\")\n",
    "                else:\n",
    "                    try:\n",
    "                        while row.table_name not in [\n",
    "                            \"filing_list\",\n",
    "                            \"individual_report_links\",\n",
    "                        ]:\n",
    "                            # remove dup rows w/ same values\n",
    "                            df_table = df_table.drop_duplicates()\n",
    "                            # tranpose da pandas df!\n",
    "                            df_table = df_table.T\n",
    "                            # transform that first rows into the header!\n",
    "                            df_table.columns = df_table.iloc[0]\n",
    "                            df_table = df_table[1:]\n",
    "                            # remove special chars again {unicode, ascii}, replace empty spaces with _\n",
    "                            df_table = df_table.rename(\n",
    "                                columns=lambda x: re.sub(\"\\W+\", \"_\", str(x))\n",
    "                            )\n",
    "                            df_table.columns = df_table.columns.str.strip(\"_\")\n",
    "                            df_table.columns = df_table.columns.str.lower(\"_\")\n",
    "                            # convert idx of df into a col\n",
    "                            df_table.reset_index(level=0, inplace=True)\n",
    "                            # Format that dirty date col\n",
    "                            try:\n",
    "                                date_list = []\n",
    "                                for item in df_table.iloc[:, 0]:\n",
    "                                    match = re.search(\"\\D{3}. \\d{2}, \\d{4}\", item)\n",
    "                                    if match is not None:\n",
    "                                        # .strftime removes the timestamp\n",
    "                                        date = parser.parse(match.group()).strftime(\n",
    "                                            \"%Y-%m-%d\"\n",
    "                                        )\n",
    "                                        date_list.append(date)\n",
    "                                    else:\n",
    "                                        date_list.append(item)\n",
    "                                df_table.rename(\n",
    "                                    columns={df_table.columns[0]: \"date\"}, inplace=True\n",
    "                                )\n",
    "                                df_table[\"date\"] = date_list\n",
    "                                print(\"Successfully formatted the date.\")\n",
    "                            except Exception as e:\n",
    "                                df_table.rename(\n",
    "                                    columns={df_table.columns[0]: \"name\"}, inplace=True\n",
    "                                )\n",
    "                                print(e)\n",
    "\n",
    "                            # convert rows to numeric dtypes (ints, floats)\n",
    "                            df_table.replace(\",\", \"\", regex=True, inplace=True)\n",
    "                            df_table = df_table.apply(pd.to_numeric, errors=\"ignore\")\n",
    "                            # rename duplicate rows w/ same name\n",
    "                            if any(df_table.columns.duplicated()):\n",
    "                                print(\n",
    "                                    \"Duplicate column name detected.\\nRenaming the duplicate column name.  \"\n",
    "                                )\n",
    "                                columns_series = pd.Series(df_table.columns)\n",
    "                                for dup in columns_series[\n",
    "                                    columns_series.duplicated()\n",
    "                                ].unique():\n",
    "                                    columns_series[\n",
    "                                        columns_series[\n",
    "                                            columns_series == dup\n",
    "                                        ].index.values.tolist()\n",
    "                                    ] = [\n",
    "                                        dup + \".\" + str(i) if i != 0 else dup\n",
    "                                        for i in range(sum(columns_series == dup))\n",
    "                                    ]\n",
    "                                    df_table.columns = columns_series\n",
    "                                break\n",
    "                    except Exception as e:\n",
    "                        print(f\"Couldnt transpose the table :|.\\n{e}\")\n",
    "                    else:\n",
    "                        with DB_Connection.open_con(db2_path) as conn2:\n",
    "                            # chk to see if table already exists in db\n",
    "                            with closing(conn2.cursor()) as cursor:\n",
    "                                cursor.execute(\n",
    "                                    f\"\"\" SELECT count(name)\n",
    "                                               FROM sqlite_master\n",
    "                                               WHERE type='table' AND name= '{row.table_name}'\"\"\"\n",
    "                                )  # SQL INJECTOIN MUCH\n",
    "                                # if count is 1, then table exists\n",
    "                                if cursor.fetchone()[0] == 1 and row.table_name not in [\n",
    "                                    \"filing_list\",\n",
    "                                    \"individual_report_links\",\n",
    "                                ]:\n",
    "                                    print(f\"Table {row.rable_name} already exists.\")\n",
    "                                else:\n",
    "                                    try:\n",
    "                                        print(f\"Connected to {db2_path} database.\")\n",
    "                                        print(\n",
    "                                            f\"Inserting data from the dataframe into SQL table {row.table_name}\"\n",
    "                                        )\n",
    "                                        # write records that are stored in the df into sql db\n",
    "                                        df_table.to_sql(\n",
    "                                            con=conn2,\n",
    "                                            name=row.table_name,\n",
    "                                            schema=\"SCHEMA\",\n",
    "                                            if_exists=\"replace\",\n",
    "                                            index=False,\n",
    "                                        )\n",
    "                                    except Exception as e:\n",
    "                                        print(\n",
    "                                            f\"Couldnt migrate the {row.table_name} \\\n",
    "                                                 table to the normalized SQL db.\\n{e}\"\n",
    "                                        )\n",
    "        DB_Connection.close_conn()\n",
    "# connection1 = DB_Connection(db_name, folder_path, db_path)\n",
    "# connection1.create_folder()\n",
    "# filings1 = Filing_Links(company_CIKs, filing_types, start_date, end_date)\n",
    "# filings1.Get_FLinks()\n",
    "# filings1.get_table_links()\n",
    "# data1 = Extract_Data()\n",
    "# data1.get_tables()\n",
    "# data1.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def req_response():\n",
    "#     for CIK_Number in self.company_CIKs:\n",
    "#         for FilingType in self.filing_types:\n",
    "#             filing_params = PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp = req.get(url = URL, pgarams = )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('SECdb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ce1c4be133a6f07ad6bfb41eebcdb3f7f6825b5feb5dee803c50a0778c3e413"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
